
# BrainLift 4 (AI Agents and Features for CRM)

## Purpose

- Look into different AI features and workflows  
  - Decide which one provides the most value  
  - And which one makes the most sense  
- Research in AI Agents  
  - What they are exactly  
  - The good and bad  
  - Current landscape or implementations  

## Experts

### David Ferrucci  
- [Wikipedia](https://en.wikipedia.org/wiki/David_Ferrucci)  
- Lead developer behind IBM Watson  
  - Cognitive computing system designed to process and analyze vast amounts of data, including natural language, to provide accurate and relevant responses  
  - Pipeline to process a request:  
    - **Question analysis** (break down input into keywords/phrases)  
    - **Hypothesis generation** (generate set of possible answers)  
    - **Evidence retrieval** (get info from training data)  
    - **Score & Rank** (evaluate confidence of each hypothesis based on evidence)  
  - **Beliefs on AI Agents**  
    - Should be designed to **augment** human capabilities, not replace them  
      - Automate routine tasks, freeing humans to focus on more creative and high-value tasks  
    - Should provide **clear explanations** for their decisions and actions  
      - Allowing users to understand and trust the output  
    - Should be based on **cognitive architecture**  
      - Modeled from human cognition, to better reason and interact with humans  

### Andrew Ng  
- [Website](https://www.andrewng.org/)  
- AI pioneer / Founder of Coursera  
- Led AI efforts for Google Brain, Baidu, [Landing.ai](http://landing.ai/), etc.  
- **Beliefs**  
  - AI Agents help bring AI to everyone  
  - AI systems need to be **safe and reliable**  
    - Development of AI that is **transparent, explainable, and fair**  
  - AI Agents should be **designed to collaborate** with humans, not replace them  
    - Used to **augment** human capabilities  

### Fei-Fei Li  
- [Wikipedia](https://en.wikipedia.org/wiki/Fei-Fei_Li)  
- Renowned computer scientist  
  - Director of **Stanford Artificial Intelligence Lab (SAIL)**  
- **Beliefs**  
  - AI Agents should **augment** human capabilities, rather than replace them  
    - Should improve human life, rather than just automate tasks that humans can already do  
  - **Transparency and Explainability** in AI systems is critical  
    - AI agents should provide **clear explanations** for their decisions and actions  
    - Enables humans to **trust** the output  
  - AI should be **inclusive and diverse**  

### Yann Lecun  
- [Wikipedia](https://en.wikipedia.org/wiki/Yann_LeCun)  
- Director of AI Research at Facebook  
- **Beliefs**  
  - AI Agents should **learn from raw data** without human supervision  
    - Essential for building more flexible agents  
    - Should learn from multiple sources of data  
  - AI Agents should be designed with **cognitive architectures**, inspired by the human brain  
  - **AI Ethics**  
    - Stresses importance of **bias, fairness, and transparency**  
    - AI systems should be **transparent, explainable, and fair**  

### Stuart Russell  
- [Website](https://people.eecs.berkeley.edu/~russell/)  
- CS Professor at UC Berkeley  
- **Beliefs**  
  - AI Agents should be **aligned with human values**  
  - Should be able to **reason about uncertainty** and make decisions under uncertainty  
    - Not just rely on deterministic models  
  - Should be designed to **collaborate** with humans  
    - Requires AI systems to understand **human intentions, values, and goals**  
  - Should be **safe, secure, and transparent**  
    - Need to develop new methods for **controlling and regulating AI systems**  

## SpikyPOVs  

- **Truth:** Agents and LLMs aren't that much different  
- **Truth:** Agents take actions on behalf of a user, whereas LLMs take input and give back output  
- **Truth:** Agents at a high level are easy to understand, but to implement, I'll soon find out  
- **Myth:** Agents acting on behalf of the user should be fully autonomous  
- **Myth:** Agents should be like LLMs, a black box that users should inherently trust  
- **Myth:** Agents should know what to do and what actions to take from the jump  
- **Truth:** Agents should take away the burden of easy/repetitive work from the user and be **trustworthy** in their results while doing so  

## Knowledge Tree / Categories  

- **Types of Agent Flows (through LangSmith)**  
  - **Prompt chaining**  
  - **Parallelization**  
  - **Routing**  
  - **Orchestrator-Worker**  
  - **Evaluator-Optimizer**  
  - **Agent**  
  - [YouTube Video](https://www.youtube.com/watch?v=Z3V7drRuNxI)  

## Impact  

- Again, I'm a bit confused on this—how should we be using our **BrainLift** / implementing it?  
  - Would be nice to have a **walkthrough or demo** on this soon  
- Help design and build out an **AI agent/system** based on **SpikyPOVs**  
  - Lay out **expectations** for the system and **requirements** going into it  

